services:
  playnode:
    image: "public.ecr.aws/j7l3n4i5/client/flask-app-${ENV:-prod}:v1.0.3"
    container_name: playnode
    networks:
      - my-network
    ports:
      - "3000:3000"
    env_file:
      - .env
    environment:
      - FLASK_APP=app.py
      - TORCHSERVE_PORT=8083
      - HOST_NAME=torchserve
    depends_on:
      - torchserve
      - postprocessing

  torchserve:
    image: "public.ecr.aws/j7l3n4i5/playai-node-ai-engine-public-${ENV:-prod}:inference-v1.0.0"
    container_name: torchserve
    networks:
      - my-network
    environment:
      - TORCHSERVE_PORT=8083
    ports:
      - "8083:8083"          # Bind the inference port
      - "8084:8084"          # Bind the management port


  postprocessing:
      image: "public.ecr.aws/j7l3n4i5/playai-node-ai-engine-public-${ENV:-prod}:postprocessing-v1.0.0"
      container_name: postprocessing
      networks:
        - my-network
      command:
        - "postprocess_lambda_function.lambda_handler"
      ports:
        - "8080:8080"
networks:
  my-network:
    driver: bridge
